模型超参优化:

Grid search
遍历所有可能的参数组合。网格搜索很容易理解和实现，例如我们的超参数A有2种选择，超参数B有3种选择，超参数C有5种选择，那么我们所有的超参数组合就有2 * 3 * 5也就是30种，我们需要遍历这30种组合并且找到其中最优的方案，对于连续值我们还需要等间距采样。实际上这30种组合不一定取得全局最优解，而且计算量很大很容易组合爆炸，并不是一种高效的参数调优方法。

Random search
限定搜索次数，随机选择参数进行实验。业界公认的Random search效果会比Grid search好，Random search其实就是随机搜索，例如前面的场景A有2种选择、B有3种、C有5种、连续值随机采样，那么每次分别在A、B、C中随机取值组合成新的超参数组合来训练。虽然有随机因素，但随机搜索可能出现效果特别差、也可能出现效果特别好，在尝试次数和Grid search相同的情况下一般最值会更大

Bayesian Optimization
Git link: https://github.com/fmfn/BayesianOptimization
业界的很多参数调优系统都是基于贝叶斯优化的，如Google Vizier , SigOpt.
该算法要求已经存在几个样本点（一开始可以采用随机搜索来确定几个初始点），并且通过高斯过程回归（假设超参数间符合联合高斯分布）计算前面n个点的后验概率分布，得到每一个超参数在每一个取值点的期望均值和方差，其中均值代表这个点最终的期望效果，均值越大表示模型最终指标越大，方差表示这个点的效果不确定性，方差越大表示这个点不确定是否可能取得最大值非常值得去探索。


